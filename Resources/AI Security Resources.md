# AI Security Resources

A curated list of resources for learning about and staying up-to-date with AI security.

## Books

- **["Artificial Intelligence Safety and Security"](https://www.amazon.com/Artificial-Intelligence-Security-Chapman-Robotics/dp/0815369824)** - Provides an overview of various safety and security concerns related to artificial intelligence.

- **["Must Learn AI Security"](https://github.com/rod-trent/OpenAISecurity/blob/main/Must_Learn/Book_Version/Must%20Learn%20AI%20Security%20Book.pdf)** - A book by the highly knowledgeable and respected Rod Trent. His [GitHub](https://github.com/rod-trent/OpenAISecurity) repo is a goldmine full of valuable learning resources
  
## Articles and Papers

- **["Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning"](https://arxiv.org/pdf/1712.03141.pdf)** - Provides an overview of adversarial machine learning techniques and their implications for security.

- **["The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation"](https://arxiv.org/pdf/1802.07228.pdf)** - Discusses potential malicious uses of AI and strategies for mitigating associated risks.

- **["Securing Machine Learning Algorithms"](https://air.unimi.it/retrieve/dfa8b9a8-d4b0-748b-e053-3a05fe0a3a96/ENISA%20Report%20-%20Securing%20Machine%20Learning%20Algorithms.pdf)** - Discover essential strategies and techniques for safeguarding the integrity and security of machine learning algorithms in various applications.


## Tools

- **[CleverHans](https://github.com/cleverhans-lab/cleverhans)** - A Python library for testing and benchmarking machine learning models' vulnerability to adversarial attacks.

- **[IBM Adversarial Robustness Toolbox (ART)](https://research.ibm.com/projects/adversarial-robustness-toolbox)** - An open-source toolkit for adversarial machine learning security.

- **[AI Incident Database](https://incidentdatabase.ai/)** - The AI Incident Database is dedicated to indexing the collective history of harms or near harms realized in the real world by the deployment of artificial intelligence systems. 

- **[AI Risk Database](https://airisk.io/)** - The AI Risk Database is a tool for discovering and reporting the risks associated with public machine learning models.

- **[OWASP LLM Security Checklist](https://owasp.org/www-project-top-10-for-large-language-model-applications/llm-top-10-governance-doc/LLM_AI_Security_and_Governance_Checklist-v1.pdf)** - The OWASP LLM Security Checklist provides a comprehensive list of security considerations and best practices specifically tailored for the development and deployment of Large Language Models.

- **[PyRit](https://github.com/Azure/PyRIT)** - The Python Risk Identification Tool for generative AI (PyRIT) is an open access automation framework to empower security professionals and ML engineers to red team foundation models and their applications.

## Threat Intel

- **[ATLAS Matrix](https://atlas.mitre.org/matrices/ATLAS/)** - The ATLAS Matrix (based on the MITRE ATT&CK framework) is the authoritative resource aiding cybersecurity professionals, data scientists, and companies to track and counter adversarial machine learning attacks.

- **[OWASP ML Security Top 10](https://owasp.org/www-project-machine-learning-security-top-10/)** - Delivers an overview of the top 10 security issues of machine learning systems.

- **[OWASP LLM Security Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/)** - The OWASP Top 10 for Large Language Model Applications project aims to educate developers, designers, architects, managers, and organizations about the potential security risks when deploying and managing Large Language Models (LLMs).









