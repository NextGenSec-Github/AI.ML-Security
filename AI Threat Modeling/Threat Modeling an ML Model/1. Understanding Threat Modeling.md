# Understanding Threat Modeling
Threat modeling is a structured approach to identifying, evaluating, and mitigating potential security threats to a system. When applied to machine learning (ML) models, threat modeling helps in understanding the various vulnerabilities and risks associated with the model's development, deployment, and usage.

## What is Threat Modeling?
Threat modeling involves systematically identifying potential threats, determining their potential impact, and devising strategies to mitigate them. It helps in proactively addressing security concerns rather than reacting to them after an incident occurs. In the context of ML models, threat modeling is crucial due to the sensitivity of data, potential biases, and susceptibility to adversarial attacks.

![](https://learn.microsoft.com/en-us/security/engineering/media/threat-modeling-aiml/tm10.jpg)

## Types of Threats in ML Models
### 1. Data Poisoning:
Data poisoning involves the injection of malicious data into the training dataset to manipulate the behavior of the ML model. Attackers can introduce subtle changes to the training data to influence the model's output during inference.

### 2. Adversarial Attacks:
Adversarial attacks involve intentionally perturbing input data to mislead the ML model's predictions. These attacks can exploit vulnerabilities in the model's decision boundary and lead to incorrect classifications.

### 3. Model Inversion:
Model inversion attacks aim to reverse-engineer sensitive information from the ML model's output. Attackers leverage the model's predictions to infer details about the training data or extract sensitive features.

## Common Threat Modeling Methodologies
### 1. STRIDE:
STRIDE is a mnemonic acronym that represents six categories of threats: Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, and Elevation of Privilege. This methodology helps in systematically categorizing threats based on their characteristics.

### 2. DREAD:
DREAD is a risk assessment model that evaluates threats based on five criteria: Damage potential, Reproducibility, Exploitability, Affected users, and Discoverability. It provides a quantitative framework for prioritizing threats and determining the appropriate mitigation measures.
